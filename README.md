# ğŸš€ **NeuroSeek: AI-Powered Knowledge Retrieval & Search**  

### ğŸ” **Overview**  
NeuroSeek is an AI-driven **search and retrieval pipeline** that leverages:  
âœ… **Web Scraping** â€“ Extracts structured data efficiently while filtering noise.  
âœ… **Vector Databases (FAISS)** â€“ Enables fast and relevant similarity search.  
âœ… **LLM Integration (Groq API)** â€“ Generates intelligent responses from extracted data.  
âœ… **Agent Orchestration** â€“ Uses multiple agents to optimize retrieval and response quality.  
âœ… **Human-in-the-Loop** â€“ UI allows users to interactively refine and improve search results.  
âœ… **Real-Time Streaming** â€“ Provides immediate feedback and response streaming.  

---

## ğŸ“Œ **Features**  

ğŸ”¹ **Intelligent Search** â€“ Retrieves and ranks results based on vector similarity.  
ğŸ”¹ **Contextual AI Responses** â€“ Uses LLMs to enhance search with dynamic answers.  
ğŸ”¹ **Adaptive Learning** â€“ Filters ads/noise and prioritizes relevant content.  
ğŸ”¹ **Interactive UI (Streamlit)** â€“ Enables user feedback and query refinement.  
ğŸ”¹ **Efficient Web Scraping** â€“ Uses structured scraping techniques for clean data.  

---

## ğŸ“ **Project Structure**  

```
ğŸ“‚ neuroseek  
â”‚â”€â”€ ğŸ“œ app.py                # Streamlit UI for interactive search  
â”‚â”€â”€ ğŸ“œ rag.py                # Retrieval-Augmented Generation pipeline  
â”‚â”€â”€ ğŸ“œ scraper.py            # Web scraper for collecting knowledge base  
â”‚â”€â”€ ğŸ“œ vectorstore.py        # FAISS-based vector database operations  
â”‚â”€â”€ ğŸ“œ requirements.txt      # Required dependencies  
â”‚â”€â”€ ğŸ“œ README.md             # Project documentation  
```

---

## ğŸ› ï¸ **Setup & Installation**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/yourusername/neuroseek.git
cd neuroseek
```

### **2ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up API Keys**  
Create a `.env` file in the root directory and add:  
```
GROQ_API_KEY=your_api_key_here
```

---

## ğŸš€ **How to Run**  

### **Start the Web Scraper**  
```bash
python scraper.py
```
ğŸ‘‰ This extracts and cleans data for search indexing.  

### **Build the Vector Store**  
```bash
python vectorstore.py
```
ğŸ‘‰ Indexes the scraped data into FAISS for fast retrieval.  

### **Run the Search & RAG Pipeline**  
```bash
python rag.py
```
ğŸ‘‰ Uses FAISS + LLM to generate AI-driven responses.  

### **Launch the Streamlit UI**  
```bash
streamlit run app.py
```
ğŸ‘‰ Access it in your browser at `http://localhost:8501`.  

---

## ğŸ”— **Live Demo**  
[Streamlit App](https://your-streamlit-app-link)  
